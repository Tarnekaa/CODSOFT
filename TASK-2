# ğŸ“ Student Project: Credit Card Fraud Detection
# ğŸ§  Idea: Use ML to spot fraud in credit card transactions
# ğŸ› ï¸ Models: Logistic Regression, Decision Tree, Random Forest
# ğŸ¤ Written in a friendly, student style!

# Step 1: Import the libraries (our toolbox ğŸ§°)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Step 2: Load the dataset ğŸ“‚
# Make sure you have a CSV file with a 'Class' column (1 = fraud, 0 = legit)
df = pd.read_csv("creditcard.csv")  # Replace with your dataset path
print("ğŸ“Š Dataset shape:", df.shape)
print("ğŸ‘€ First few rows:\n", df.head())

# Step 3: Split features and target ğŸ¯
X = df.drop("Class", axis=1)  # Features (transaction details)
y = df["Class"]               # Target (fraud or legit)

# Step 4: Train-test split âœ‚ï¸
# 80% for training, 20% for testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Step 5: Scale features (important for Logistic Regression) âš–ï¸
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 6: Function to train & evaluate models ğŸ§ª
def train_and_evaluate(model, name, X_tr, X_te):
    print(f"\nğŸš€ Training: {name}")
    model.fit(X_tr, y_train)
    y_pred = model.predict(X_te)

    # Results time ğŸ‰
    print("âœ… Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("ğŸ“‹ Classification Report:\n", classification_report(y_test, y_pred))
    print("ğŸ“ˆ ROC-AUC Score:", roc_auc_score(y_test, y_pred))

# Step 7: Logistic Regression (simple but powerful ğŸ’¡)
lr = LogisticRegression(max_iter=1000, class_weight="balanced")
train_and_evaluate(lr, "Logistic Regression", X_train_scaled, X_test_scaled)

# Step 8: Decision Tree (easy to visualize ğŸŒ³)
dt = DecisionTreeClassifier(class_weight="balanced", random_state=42)
train_and_evaluate(dt, "Decision Tree", X_train, X_test)

# Step 9: Random Forest (lots of trees working together ğŸŒ²ğŸŒ²ğŸŒ²)
rf = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42)
train_and_evaluate(rf, "Random Forest", X_train, X_test)
